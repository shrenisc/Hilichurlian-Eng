{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "scikit-learn version 1.4.2 is not supported. Minimum required version: 0.17. Maximum required version: 1.1.2. Disabling scikit-learn conversion API.\n",
      "Torch version 2.3.0+cu121 has not been tested with coremltools. You may run into unexpected errors. Torch 2.2.0 is the most recent version that has been tested.\n",
      "/home/rahulvadhyar/.local/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Failed to load _MLModelProxy: No module named 'coremltools.libcoremlpython'\n"
     ]
    }
   ],
   "source": [
    "from model import Translator\n",
    "from dataset import TextDataset\n",
    "import torch\n",
    "import tqdm\n",
    "from tokenizers import Tokenizer\n",
    "import os\n",
    "import coremltools as ct\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch version 2.3.0+cu121\n",
      "Using device cuda\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"Using PyTorch version {torch.__version__}\")\n",
    "\n",
    "# use gpu if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device {device}\")\n",
    "\n",
    "# use tensor cores\n",
    "torch.set_float32_matmul_precision('high')\n",
    "\n",
    "# use flash attention\n",
    "torch.backends.cuda.enable_flash_sdp(False)\n",
    "torch.backends.cuda.enable_mem_efficient_sdp(False)\n",
    "torch.backends.cuda.enable_math_sdp(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Translator(\n",
       "  (engEmbedding): Embedding(129, 256)\n",
       "  (hilliEmbedding): Embedding(129, 256)\n",
       "  (decoder_block): ModuleList(\n",
       "    (0-6): 7 x Decoder(\n",
       "      (feed_forward): Sequential(\n",
       "        (0): Dropout(p=0.1, inplace=False)\n",
       "        (1): Linear(in_features=256, out_features=512, bias=False)\n",
       "        (2): ReLU()\n",
       "        (3): Linear(in_features=512, out_features=256, bias=False)\n",
       "        (4): ReLU()\n",
       "      )\n",
       "      (layernorm): RMSNorm()\n",
       "      (layernorm2): RMSNorm()\n",
       "      (layernorm3): RMSNorm()\n",
       "      (MHA): SelfAttention(\n",
       "        (c_attn): Linear(in_features=256, out_features=768, bias=False)\n",
       "        (c_proj): Linear(in_features=256, out_features=256, bias=False)\n",
       "        (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (CA): CrossAttention(\n",
       "        (query_attn): Linear(in_features=256, out_features=256, bias=False)\n",
       "        (key_attn): Linear(in_features=256, out_features=256, bias=False)\n",
       "        (value_attn): Linear(in_features=256, out_features=256, bias=False)\n",
       "        (c_proj): Linear(in_features=256, out_features=256, bias=False)\n",
       "        (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (encoder_block): ModuleList(\n",
       "    (0-6): 7 x Encoder(\n",
       "      (feed_forward): Sequential(\n",
       "        (0): Dropout(p=0.1, inplace=False)\n",
       "        (1): Linear(in_features=256, out_features=512, bias=False)\n",
       "        (2): ReLU()\n",
       "        (3): Linear(in_features=512, out_features=256, bias=False)\n",
       "        (4): ReLU()\n",
       "      )\n",
       "      (layernorm): RMSNorm()\n",
       "      (layernorm2): RMSNorm()\n",
       "      (MHA): SelfAttention(\n",
       "        (c_attn): Linear(in_features=256, out_features=768, bias=False)\n",
       "        (c_proj): Linear(in_features=256, out_features=256, bias=False)\n",
       "        (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dense): Linear(in_features=256, out_features=129, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Translator(engVocabSize=129, hilliVocabSize=129, embed_size=256,\n",
    "                   num_encoder_blocks=7, num_decoder_blocks=7, num_heads=8, dropout=0.1, pad_char=2)\n",
    "model.load_state_dict(torch.load(\"../models/model.pt\").state_dict())\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rahulvadhyar/Documents/Hilichurlian-Eng/src/model.py:112: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert query_batch == key_batch == value_batch\n",
      "/home/rahulvadhyar/Documents/Hilichurlian-Eng/src/model.py:113: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert query_channels == key_channels == value_channels\n"
     ]
    }
   ],
   "source": [
    "model = torch.jit.trace(model, (torch.randint(0, 129, (1, 500,)), torch.randint(0, 129, (1, 500,))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.jit.script(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting PyTorch Frontend ==> MIL Ops:   0%|          | 0/3301 [00:00<?, ? ops/s]Saving value type of int64 into a builtin type of int32, might lose precision!\n",
      "Saving value type of int64 into a builtin type of int32, might lose precision!\n",
      "Saving value type of int64 into a builtin type of int32, might lose precision!\n",
      "Saving value type of int64 into a builtin type of int32, might lose precision!\n",
      "Saving value type of int64 into a builtin type of int32, might lose precision!\n",
      "Saving value type of int64 into a builtin type of int32, might lose precision!\n",
      "Saving value type of int64 into a builtin type of int32, might lose precision!\n",
      "Saving value type of int64 into a builtin type of int32, might lose precision!\n",
      "Converting PyTorch Frontend ==> MIL Ops:   8%|▊         | 278/3301 [00:00<00:01, 2779.61 ops/s]Saving value type of int64 into a builtin type of int32, might lose precision!\n",
      "Saving value type of int64 into a builtin type of int32, might lose precision!\n",
      "Saving value type of int64 into a builtin type of int32, might lose precision!\n",
      "Saving value type of int64 into a builtin type of int32, might lose precision!\n",
      "Saving value type of int64 into a builtin type of int32, might lose precision!\n",
      "Converting PyTorch Frontend ==> MIL Ops:  17%|█▋        | 556/3301 [00:00<00:01, 2174.31 ops/s]Saving value type of int64 into a builtin type of int32, might lose precision!\n",
      "Saving value type of int64 into a builtin type of int32, might lose precision!\n",
      "Saving value type of int64 into a builtin type of int32, might lose precision!\n",
      "Saving value type of int64 into a builtin type of int32, might lose precision!\n",
      "Saving value type of int64 into a builtin type of int32, might lose precision!\n",
      "Saving value type of int64 into a builtin type of int32, might lose precision!\n",
      "Saving value type of int64 into a builtin type of int32, might lose precision!\n",
      "Converting PyTorch Frontend ==> MIL Ops:  25%|██▍       | 811/3301 [00:00<00:01, 1944.48 ops/s]Saving value type of int64 into a builtin type of int32, might lose precision!\n",
      "Saving value type of int64 into a builtin type of int32, might lose precision!\n",
      "Saving value type of int64 into a builtin type of int32, might lose precision!\n",
      "Saving value type of int64 into a builtin type of int32, might lose precision!\n",
      "Saving value type of int64 into a builtin type of int32, might lose precision!\n",
      "Saving value type of int64 into a builtin type of int32, might lose precision!\n",
      "Saving value type of int64 into a builtin type of int32, might lose precision!\n",
      "Saving value type of int64 into a builtin type of int32, might lose precision!\n",
      "Converting PyTorch Frontend ==> MIL Ops:  34%|███▍      | 1126/3301 [00:00<00:00, 2330.54 ops/s]Saving value type of int64 into a builtin type of int32, might lose precision!\n",
      "Saving value type of int64 into a builtin type of int32, might lose precision!\n",
      "Saving value type of int64 into a builtin type of int32, might lose precision!\n",
      "Saving value type of int64 into a builtin type of int32, might lose precision!\n",
      "Saving value type of int64 into a builtin type of int32, might lose precision!\n",
      "Saving value type of int64 into a builtin type of int32, might lose precision!\n",
      "Converting PyTorch Frontend ==> MIL Ops:  42%|████▏     | 1372/3301 [00:00<00:00, 2084.63 ops/s]Saving value type of int64 into a builtin type of int32, might lose precision!\n",
      "Saving value type of int64 into a builtin type of int32, might lose precision!\n",
      "Saving value type of int64 into a builtin type of int32, might lose precision!\n",
      "Saving value type of int64 into a builtin type of int32, might lose precision!\n",
      "Saving value type of int64 into a builtin type of int32, might lose precision!\n",
      "Saving value type of int64 into a builtin type of int32, might lose precision!\n",
      "Saving value type of int64 into a builtin type of int32, might lose precision!\n",
      "Saving value type of int64 into a builtin type of int32, might lose precision!\n",
      "Converting PyTorch Frontend ==> MIL Ops:  51%|█████     | 1676/3301 [00:00<00:00, 2354.86 ops/s]Saving value type of int64 into a builtin type of int32, might lose precision!\n",
      "Saving value type of int64 into a builtin type of int32, might lose precision!\n",
      "Saving value type of int64 into a builtin type of int32, might lose precision!\n",
      "Saving value type of int64 into a builtin type of int32, might lose precision!\n",
      "Saving value type of int64 into a builtin type of int32, might lose precision!\n",
      "Saving value type of int64 into a builtin type of int32, might lose precision!\n",
      "Saving value type of int64 into a builtin type of int32, might lose precision!\n",
      "Saving value type of int64 into a builtin type of int32, might lose precision!\n",
      "Converting PyTorch Frontend ==> MIL Ops:  60%|█████▉    | 1977/3301 [00:00<00:00, 2543.23 ops/s]Saving value type of int64 into a builtin type of int32, might lose precision!\n",
      "Saving value type of int64 into a builtin type of int32, might lose precision!\n",
      "Saving value type of int64 into a builtin type of int32, might lose precision!\n",
      "Saving value type of int64 into a builtin type of int32, might lose precision!\n",
      "Saving value type of int64 into a builtin type of int32, might lose precision!\n",
      "Saving value type of int64 into a builtin type of int32, might lose precision!\n",
      "Saving value type of int64 into a builtin type of int32, might lose precision!\n",
      "Converting PyTorch Frontend ==> MIL Ops:  69%|██████▉   | 2270/3301 [00:00<00:00, 2652.65 ops/s]Saving value type of int64 into a builtin type of int32, might lose precision!\n",
      "Saving value type of int64 into a builtin type of int32, might lose precision!\n",
      "Saving value type of int64 into a builtin type of int32, might lose precision!\n",
      "Saving value type of int64 into a builtin type of int32, might lose precision!\n",
      "Saving value type of int64 into a builtin type of int32, might lose precision!\n",
      "Saving value type of int64 into a builtin type of int32, might lose precision!\n",
      "Saving value type of int64 into a builtin type of int32, might lose precision!\n",
      "Saving value type of int64 into a builtin type of int32, might lose precision!\n",
      "Converting PyTorch Frontend ==> MIL Ops:  78%|███████▊  | 2575/3301 [00:01<00:00, 2768.90 ops/s]Saving value type of int64 into a builtin type of int32, might lose precision!\n",
      "Saving value type of int64 into a builtin type of int32, might lose precision!\n",
      "Saving value type of int64 into a builtin type of int32, might lose precision!\n",
      "Saving value type of int64 into a builtin type of int32, might lose precision!\n",
      "Saving value type of int64 into a builtin type of int32, might lose precision!\n",
      "Saving value type of int64 into a builtin type of int32, might lose precision!\n",
      "Saving value type of int64 into a builtin type of int32, might lose precision!\n",
      "Saving value type of int64 into a builtin type of int32, might lose precision!\n",
      "Converting PyTorch Frontend ==> MIL Ops:  87%|████████▋ | 2884/3301 [00:01<00:00, 2863.22 ops/s]Saving value type of int64 into a builtin type of int32, might lose precision!\n",
      "Saving value type of int64 into a builtin type of int32, might lose precision!\n",
      "Saving value type of int64 into a builtin type of int32, might lose precision!\n",
      "Saving value type of int64 into a builtin type of int32, might lose precision!\n",
      "Saving value type of int64 into a builtin type of int32, might lose precision!\n",
      "Saving value type of int64 into a builtin type of int32, might lose precision!\n",
      "Saving value type of int64 into a builtin type of int32, might lose precision!\n",
      "Saving value type of int64 into a builtin type of int32, might lose precision!\n",
      "Converting PyTorch Frontend ==> MIL Ops:  97%|█████████▋| 3186/3301 [00:01<00:00, 2909.35 ops/s]Saving value type of int64 into a builtin type of int32, might lose precision!\n",
      "Saving value type of int64 into a builtin type of int32, might lose precision!\n",
      "Saving value type of int64 into a builtin type of int32, might lose precision!\n",
      "Converting PyTorch Frontend ==> MIL Ops: 100%|█████████▉| 3300/3301 [00:01<00:00, 2620.11 ops/s]\n",
      "Running MIL frontend_pytorch pipeline: 100%|██████████| 5/5 [00:00<00:00, 38.01 passes/s]\n",
      "Running MIL default pipeline:  13%|█▎        | 10/76 [00:00<00:02, 23.68 passes/s]/home/rahulvadhyar/.local/lib/python3.11/site-packages/coremltools/converters/mil/mil/passes/defs/preprocess.py:266: UserWarning: Output, '3673', of the source model, has been renamed to 'var_3673' in the Core ML model.\n",
      "  warnings.warn(msg.format(var.name, new_name))\n",
      "Running MIL default pipeline: 100%|██████████| 76/76 [00:01<00:00, 39.57 passes/s]\n",
      "Running MIL backend_neuralnetwork pipeline: 100%|██████████| 9/9 [00:00<00:00, 87.86 passes/s]\n",
      "Translating MIL ==> NeuralNetwork Ops:   8%|▊         | 159/2061 [00:00<00:01, 1541.88 ops/s]Const freqs_imag.5 was already added.\n",
      "Const freqs_real.5 was already added.\n",
      "Const freqs_real.5 was already added.\n",
      "Const freqs_imag.5 was already added.\n",
      "Const freqs_imag.5 was already added.\n",
      "Const freqs_real.5 was already added.\n",
      "Const freqs_real.5 was already added.\n",
      "Const freqs_imag.5 was already added.\n",
      "Const freqs_imag.5 was already added.\n",
      "Const freqs_real.5 was already added.\n",
      "Const freqs_real.5 was already added.\n",
      "Const freqs_imag.5 was already added.\n",
      "Const freqs_imag.5 was already added.\n",
      "Const freqs_real.5 was already added.\n",
      "Const add_0 was already added.\n",
      "Translating MIL ==> NeuralNetwork Ops:  15%|█▌        | 314/2061 [00:00<00:01, 912.70 ops/s] Const freqs_real.5 was already added.\n",
      "Const freqs_imag.5 was already added.\n",
      "Const freqs_imag.5 was already added.\n",
      "Const freqs_real.5 was already added.\n",
      "Const freqs_real.5 was already added.\n",
      "Const freqs_imag.5 was already added.\n",
      "Const freqs_imag.5 was already added.\n",
      "Const freqs_real.5 was already added.\n",
      "Const add_0 was already added.\n",
      "Translating MIL ==> NeuralNetwork Ops:  20%|██        | 420/2061 [00:00<00:02, 737.68 ops/s]Const freqs_real.5 was already added.\n",
      "Const freqs_imag.5 was already added.\n",
      "Const freqs_imag.5 was already added.\n",
      "Const freqs_real.5 was already added.\n",
      "Const freqs_real.5 was already added.\n",
      "Const freqs_imag.5 was already added.\n",
      "Const freqs_imag.5 was already added.\n",
      "Const freqs_real.5 was already added.\n",
      "Const add_0 was already added.\n",
      "Translating MIL ==> NeuralNetwork Ops:  24%|██▍       | 503/2061 [00:00<00:02, 645.21 ops/s]Const freqs_real.5 was already added.\n",
      "Const freqs_imag.5 was already added.\n",
      "Const freqs_imag.5 was already added.\n",
      "Const freqs_real.5 was already added.\n",
      "Const freqs_real.5 was already added.\n",
      "Const freqs_imag.5 was already added.\n",
      "Translating MIL ==> NeuralNetwork Ops:  28%|██▊       | 573/2061 [00:00<00:02, 542.00 ops/s]Const freqs_imag.5 was already added.\n",
      "Const freqs_real.5 was already added.\n",
      "Const add_0 was already added.\n",
      "Translating MIL ==> NeuralNetwork Ops:  31%|███       | 631/2061 [00:00<00:02, 534.38 ops/s]Const freqs_real.5 was already added.\n",
      "Const freqs_imag.5 was already added.\n",
      "Const freqs_imag.5 was already added.\n",
      "Const freqs_real.5 was already added.\n",
      "Const freqs_real.5 was already added.\n",
      "Const freqs_imag.5 was already added.\n",
      "Const freqs_imag.5 was already added.\n",
      "Const freqs_real.5 was already added.\n",
      "Const add_0 was already added.\n",
      "Translating MIL ==> NeuralNetwork Ops:  34%|███▍      | 704/2061 [00:01<00:02, 577.27 ops/s]Const freqs_real.5 was already added.\n",
      "Const freqs_imag.5 was already added.\n",
      "Const freqs_imag.5 was already added.\n",
      "Const freqs_real.5 was already added.\n",
      "Translating MIL ==> NeuralNetwork Ops:  37%|███▋      | 765/2061 [00:01<00:02, 504.93 ops/s]Const freqs_real.5 was already added.\n",
      "Const freqs_imag.5 was already added.\n",
      "Const freqs_imag.5 was already added.\n",
      "Const freqs_real.5 was already added.\n",
      "Const add_0 was already added.\n",
      "Translating MIL ==> NeuralNetwork Ops:  40%|███▉      | 819/2061 [00:01<00:02, 493.95 ops/s]Const freqs_real.5 was already added.\n",
      "Const freqs_imag.5 was already added.\n",
      "Const freqs_imag.5 was already added.\n",
      "Const freqs_real.5 was already added.\n",
      "Const freqs_real.5 was already added.\n",
      "Const freqs_imag.5 was already added.\n",
      "Const freqs_imag.5 was already added.\n",
      "Const freqs_real.5 was already added.\n",
      "Const add_0 was already added.\n",
      "Translating MIL ==> NeuralNetwork Ops:  44%|████▎     | 900/2061 [00:01<00:02, 550.58 ops/s]Const freqs_real.5 was already added.\n",
      "Const freqs_imag.5 was already added.\n",
      "Const freqs_imag.5 was already added.\n",
      "Const freqs_real.5 was already added.\n",
      "Const freqs_real.5 was already added.\n",
      "Const freqs_imag.5 was already added.\n",
      "Const freqs_imag.5 was already added.\n",
      "Const freqs_real.5 was already added.\n",
      "Translating MIL ==> NeuralNetwork Ops:  48%|████▊     | 991/2061 [00:01<00:01, 580.52 ops/s]Const freqs_real.5 was already added.\n",
      "Const freqs_imag.5 was already added.\n",
      "Const freqs_imag.5 was already added.\n",
      "Const freqs_real.5 was already added.\n",
      "Const freqs_real.5 was already added.\n",
      "Const freqs_imag.5 was already added.\n",
      "Const freqs_imag.5 was already added.\n",
      "Const freqs_real.5 was already added.\n",
      "Translating MIL ==> NeuralNetwork Ops:  51%|█████     | 1051/2061 [00:01<00:01, 557.82 ops/s]Const add_0 was already added.\n",
      "Const freqs_real.5 was already added.\n",
      "Const freqs_imag.5 was already added.\n",
      "Const freqs_imag.5 was already added.\n",
      "Const freqs_real.5 was already added.\n",
      "Const freqs_real.5 was already added.\n",
      "Const freqs_imag.5 was already added.\n",
      "Const freqs_imag.5 was already added.\n",
      "Const freqs_real.5 was already added.\n",
      "Translating MIL ==> NeuralNetwork Ops:  56%|█████▌    | 1156/2061 [00:01<00:01, 651.04 ops/s]Const freqs_real.5 was already added.\n",
      "Const freqs_imag.5 was already added.\n",
      "Const freqs_imag.5 was already added.\n",
      "Const freqs_real.5 was already added.\n",
      "Const freqs_real.5 was already added.\n",
      "Const freqs_imag.5 was already added.\n",
      "Const freqs_imag.5 was already added.\n",
      "Translating MIL ==> NeuralNetwork Ops:  59%|█████▉    | 1223/2061 [00:02<00:01, 563.00 ops/s]Const freqs_real.5 was already added.\n",
      "Const add_0 was already added.\n",
      "Const freqs_real.5 was already added.\n",
      "Const freqs_imag.5 was already added.\n",
      "Const freqs_imag.5 was already added.\n",
      "Const freqs_real.5 was already added.\n",
      "Const freqs_real.5 was already added.\n",
      "Const freqs_imag.5 was already added.\n",
      "Const freqs_imag.5 was already added.\n",
      "Const freqs_real.5 was already added.\n",
      "Translating MIL ==> NeuralNetwork Ops:  65%|██████▍   | 1333/2061 [00:02<00:01, 662.22 ops/s]Const freqs_real.5 was already added.\n",
      "Const freqs_imag.5 was already added.\n",
      "Const freqs_imag.5 was already added.\n",
      "Const freqs_real.5 was already added.\n",
      "Const freqs_real.5 was already added.\n",
      "Const freqs_imag.5 was already added.\n",
      "Const freqs_imag.5 was already added.\n",
      "Const freqs_real.5 was already added.\n",
      "Translating MIL ==> NeuralNetwork Ops:  68%|██████▊   | 1402/2061 [00:02<00:01, 578.03 ops/s]Const add_0 was already added.\n",
      "Const freqs_real.5 was already added.\n",
      "Const freqs_imag.5 was already added.\n",
      "Const freqs_imag.5 was already added.\n",
      "Const freqs_real.5 was already added.\n",
      "Const freqs_real.5 was already added.\n",
      "Const freqs_imag.5 was already added.\n",
      "Const freqs_imag.5 was already added.\n",
      "Const freqs_real.5 was already added.\n",
      "Translating MIL ==> NeuralNetwork Ops:  75%|███████▌  | 1549/2061 [00:02<00:00, 527.95 ops/s]Const freqs_real.5 was already added.\n",
      "Const freqs_imag.5 was already added.\n",
      "Const freqs_imag.5 was already added.\n",
      "Const freqs_real.5 was already added.\n",
      "Const freqs_real.5 was already added.\n",
      "Const freqs_imag.5 was already added.\n",
      "Const freqs_imag.5 was already added.\n",
      "Const freqs_real.5 was already added.\n",
      "Const add_0 was already added.\n",
      "Const freqs_real.5 was already added.\n",
      "Const freqs_imag.5 was already added.\n",
      "Const freqs_imag.5 was already added.\n",
      "Const freqs_real.5 was already added.\n",
      "Const freqs_real.5 was already added.\n",
      "Const freqs_imag.5 was already added.\n",
      "Const freqs_imag.5 was already added.\n",
      "Translating MIL ==> NeuralNetwork Ops:  80%|████████  | 1657/2061 [00:02<00:00, 653.55 ops/s]Const freqs_real.5 was already added.\n",
      "Translating MIL ==> NeuralNetwork Ops:  84%|████████▍ | 1730/2061 [00:02<00:00, 556.87 ops/s]Const freqs_real.5 was already added.\n",
      "Const freqs_imag.5 was already added.\n",
      "Const freqs_imag.5 was already added.\n",
      "Const freqs_real.5 was already added.\n",
      "Const freqs_real.5 was already added.\n",
      "Const freqs_imag.5 was already added.\n",
      "Const freqs_imag.5 was already added.\n",
      "Const freqs_real.5 was already added.\n",
      "Const add_0 was already added.\n",
      "Const freqs_real.5 was already added.\n",
      "Const freqs_imag.5 was already added.\n",
      "Const freqs_imag.5 was already added.\n",
      "Const freqs_real.5 was already added.\n",
      "Const freqs_real.5 was already added.\n",
      "Const freqs_imag.5 was already added.\n",
      "Const freqs_imag.5 was already added.\n",
      "Const freqs_real.5 was already added.\n",
      "Translating MIL ==> NeuralNetwork Ops:  90%|█████████ | 1864/2061 [00:03<00:00, 697.90 ops/s]Const freqs_real.5 was already added.\n",
      "Const freqs_imag.5 was already added.\n",
      "Const freqs_imag.5 was already added.\n",
      "Const freqs_real.5 was already added.\n",
      "Const freqs_real.5 was already added.\n",
      "Const freqs_imag.5 was already added.\n",
      "Const freqs_imag.5 was already added.\n",
      "Const freqs_real.5 was already added.\n",
      "Translating MIL ==> NeuralNetwork Ops:  94%|█████████▍| 1941/2061 [00:03<00:00, 622.52 ops/s]Const add_0 was already added.\n",
      "Const freqs_real.5 was already added.\n",
      "Const freqs_imag.5 was already added.\n",
      "Const freqs_imag.5 was already added.\n",
      "Const freqs_real.5 was already added.\n",
      "Const freqs_real.5 was already added.\n",
      "Const freqs_imag.5 was already added.\n",
      "Const freqs_imag.5 was already added.\n",
      "Const freqs_real.5 was already added.\n",
      "Translating MIL ==> NeuralNetwork Ops: 100%|██████████| 2061/2061 [00:03<00:00, 607.37 ops/s]\n"
     ]
    }
   ],
   "source": [
    "mlmodel = ct.convert(model, \n",
    "                     inputs=[ct.TensorType(name=\"x\", shape=(1, 100), dtype=np.int32), ct.TensorType(name=\"originalText\", shape=(1, 100), dtype=np.int32)],\n",
    "                     convert_to=\"neuralnetwork\",\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlmodel.save(\"model.mlmodel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running compression pass prune_weights: 100%|██████████| 95/95 [00:01<00:00, 74.91 ops/s] \n",
      "Running MIL frontend_milinternal pipeline: 0 passes [00:00, ? passes/s]\n",
      "Running MIL default pipeline: 100%|██████████| 76/76 [00:01<00:00, 39.79 passes/s]\n",
      "Running MIL backend_mlprogram pipeline: 100%|██████████| 12/12 [00:00<00:00, 102.54 passes/s]\n"
     ]
    }
   ],
   "source": [
    "from coremltools.optimize.coreml import (\n",
    "    OpMagnitudePrunerConfig,\n",
    "    OptimizationConfig,\n",
    "    prune_weights,\n",
    ")\n",
    "\n",
    "op_config = OpMagnitudePrunerConfig(\n",
    "    target_sparsity=0.6,\n",
    "    weight_threshold=1024,\n",
    ")\n",
    "config = OptimizationConfig(global_config=op_config)\n",
    "model_compressed = prune_weights(mlmodel, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running compression pass palettize_weights:   0%|          | 0/160 [00:00<?, ? ops/s]/home/rahulvadhyar/.local/lib/python3.11/site-packages/sklearn/base.py:1474: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (256). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "Running compression pass palettize_weights:   5%|▌         | 8/160 [00:00<00:06, 24.11 ops/s]/home/rahulvadhyar/.local/lib/python3.11/site-packages/sklearn/base.py:1474: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (256). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "Running compression pass palettize_weights: 100%|██████████| 160/160 [00:00<00:00, 412.06 ops/s]\n",
      "Running MIL frontend_milinternal pipeline: 0 passes [00:00, ? passes/s]\n",
      "Running MIL default pipeline: 100%|██████████| 76/76 [00:01<00:00, 39.55 passes/s]\n",
      "Running MIL backend_mlprogram pipeline: 100%|██████████| 12/12 [00:00<00:00, 72.12 passes/s]\n"
     ]
    }
   ],
   "source": [
    "from coremltools.optimize.coreml import (\n",
    "    OpPalettizerConfig,\n",
    "    OptimizationConfig,\n",
    "    palettize_weights,\n",
    ")\n",
    "\n",
    "op_config = OpPalettizerConfig(mode=\"kmeans\", nbits=8, weight_threshold=512)\n",
    "config = OptimizationConfig(global_config=op_config)\n",
    "compressed_6_bit_model = palettize_weights(model_compressed, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed_6_bit_model .save(\"model.mlpackage\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
