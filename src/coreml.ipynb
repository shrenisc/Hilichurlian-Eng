{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import Translator\n",
    "from dataset import TextDataset\n",
    "import torch\n",
    "import tqdm\n",
    "from tokenizers import Tokenizer\n",
    "import os\n",
    "import coremltools as ct\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch version 2.3.0+cu121\n",
      "Using device cuda\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"Using PyTorch version {torch.__version__}\")\n",
    "\n",
    "# use gpu if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device {device}\")\n",
    "\n",
    "# use tensor cores\n",
    "torch.set_float32_matmul_precision('high')\n",
    "\n",
    "# use flash attention\n",
    "torch.backends.cuda.enable_flash_sdp(False)\n",
    "torch.backends.cuda.enable_mem_efficient_sdp(False)\n",
    "torch.backends.cuda.enable_math_sdp(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Translator(\n",
       "  (engEmbedding): Embedding(804, 256)\n",
       "  (hilliEmbedding): Embedding(292, 256)\n",
       "  (decoder_block): ModuleList(\n",
       "    (0-4): 5 x Decoder(\n",
       "      (feed_forward): Sequential(\n",
       "        (0): Dropout(p=0.1, inplace=False)\n",
       "        (1): Linear(in_features=256, out_features=512, bias=False)\n",
       "        (2): ReLU()\n",
       "        (3): Linear(in_features=512, out_features=256, bias=False)\n",
       "        (4): ReLU()\n",
       "      )\n",
       "      (layernorm): RMSNorm()\n",
       "      (layernorm2): RMSNorm()\n",
       "      (layernorm3): RMSNorm()\n",
       "      (MHA): SelfAttention(\n",
       "        (c_attn): Linear(in_features=256, out_features=768, bias=False)\n",
       "        (c_proj): Linear(in_features=256, out_features=256, bias=False)\n",
       "        (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (CA): CrossAttention(\n",
       "        (query_attn): Linear(in_features=256, out_features=256, bias=False)\n",
       "        (key_attn): Linear(in_features=256, out_features=256, bias=False)\n",
       "        (value_attn): Linear(in_features=256, out_features=256, bias=False)\n",
       "        (c_proj): Linear(in_features=256, out_features=256, bias=False)\n",
       "        (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (encoder_block): ModuleList(\n",
       "    (0-4): 5 x Encoder(\n",
       "      (feed_forward): Sequential(\n",
       "        (0): Dropout(p=0.1, inplace=False)\n",
       "        (1): Linear(in_features=256, out_features=512, bias=False)\n",
       "        (2): ReLU()\n",
       "        (3): Linear(in_features=512, out_features=256, bias=False)\n",
       "        (4): ReLU()\n",
       "      )\n",
       "      (layernorm): RMSNorm()\n",
       "      (layernorm2): RMSNorm()\n",
       "      (MHA): SelfAttention(\n",
       "        (c_attn): Linear(in_features=256, out_features=768, bias=False)\n",
       "        (c_proj): Linear(in_features=256, out_features=256, bias=False)\n",
       "        (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dense): Linear(in_features=256, out_features=804, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Translator(engVocabSize=804, hilliVocabSize=292, embed_size=256,\n",
    "                   num_encoder_blocks=5, num_decoder_blocks=5, num_heads=8, dropout=0.1, pad_char=2)\n",
    "model.load_state_dict(torch.load(\"../models/model.pt\").state_dict())\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rahulvadhyar/Documents/Hilichurlian-Eng/src/model.py:112: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert query_batch == key_batch == value_batch\n",
      "/home/rahulvadhyar/Documents/Hilichurlian-Eng/src/model.py:113: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert query_channels == key_channels == value_channels\n"
     ]
    }
   ],
   "source": [
    "model = torch.jit.trace(model, (torch.randint(0, 804, (1, 100,)), torch.randint(0, 292, (1, 100,))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.jit.script(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting PyTorch Frontend ==> MIL Ops:   0%|          | 0/2361 [00:00<?, ? ops/s]Saving value type of int64 into a builtin type of int32, might lose precision!\n",
      "Saving value type of int64 into a builtin type of int32, might lose precision!\n",
      "Saving value type of int64 into a builtin type of int32, might lose precision!\n",
      "Saving value type of int64 into a builtin type of int32, might lose precision!\n",
      "Converting PyTorch Frontend ==> MIL Ops:   6%|▋         | 152/2361 [00:00<00:01, 1518.65 ops/s]Saving value type of int64 into a builtin type of int32, might lose precision!\n",
      "Saving value type of int64 into a builtin type of int32, might lose precision!\n",
      "Saving value type of int64 into a builtin type of int32, might lose precision!\n",
      "Saving value type of int64 into a builtin type of int32, might lose precision!\n",
      "Saving value type of int64 into a builtin type of int32, might lose precision!\n",
      "Converting PyTorch Frontend ==> MIL Ops:  17%|█▋        | 391/2361 [00:00<00:00, 2026.67 ops/s]Saving value type of int64 into a builtin type of int32, might lose precision!\n",
      "Saving value type of int64 into a builtin type of int32, might lose precision!\n",
      "Saving value type of int64 into a builtin type of int32, might lose precision!\n",
      "Saving value type of int64 into a builtin type of int32, might lose precision!\n",
      "Saving value type of int64 into a builtin type of int32, might lose precision!\n",
      "Converting PyTorch Frontend ==> MIL Ops:  25%|██▌       | 594/2361 [00:00<00:01, 1679.44 ops/s]Saving value type of int64 into a builtin type of int32, might lose precision!\n",
      "Saving value type of int64 into a builtin type of int32, might lose precision!\n",
      "Saving value type of int64 into a builtin type of int32, might lose precision!\n",
      "Saving value type of int64 into a builtin type of int32, might lose precision!\n",
      "Saving value type of int64 into a builtin type of int32, might lose precision!\n",
      "Saving value type of int64 into a builtin type of int32, might lose precision!\n",
      "Converting PyTorch Frontend ==> MIL Ops:  34%|███▍      | 811/2361 [00:00<00:00, 1602.06 ops/s]Saving value type of int64 into a builtin type of int32, might lose precision!\n",
      "Saving value type of int64 into a builtin type of int32, might lose precision!\n",
      "Saving value type of int64 into a builtin type of int32, might lose precision!\n",
      "Saving value type of int64 into a builtin type of int32, might lose precision!\n",
      "Saving value type of int64 into a builtin type of int32, might lose precision!\n",
      "Saving value type of int64 into a builtin type of int32, might lose precision!\n",
      "Saving value type of int64 into a builtin type of int32, might lose precision!\n",
      "Saving value type of int64 into a builtin type of int32, might lose precision!\n",
      "Converting PyTorch Frontend ==> MIL Ops:  47%|████▋     | 1098/2361 [00:00<00:00, 1983.81 ops/s]Saving value type of int64 into a builtin type of int32, might lose precision!\n",
      "Saving value type of int64 into a builtin type of int32, might lose precision!\n",
      "Saving value type of int64 into a builtin type of int32, might lose precision!\n",
      "Saving value type of int64 into a builtin type of int32, might lose precision!\n",
      "Converting PyTorch Frontend ==> MIL Ops:  55%|█████▌    | 1307/2361 [00:00<00:00, 1948.70 ops/s]Saving value type of int64 into a builtin type of int32, might lose precision!\n",
      "Saving value type of int64 into a builtin type of int32, might lose precision!\n",
      "Saving value type of int64 into a builtin type of int32, might lose precision!\n",
      "Saving value type of int64 into a builtin type of int32, might lose precision!\n",
      "Saving value type of int64 into a builtin type of int32, might lose precision!\n",
      "Saving value type of int64 into a builtin type of int32, might lose precision!\n",
      "Saving value type of int64 into a builtin type of int32, might lose precision!\n",
      "Saving value type of int64 into a builtin type of int32, might lose precision!\n",
      "Converting PyTorch Frontend ==> MIL Ops:  67%|██████▋   | 1585/2361 [00:00<00:00, 1586.13 ops/s]Saving value type of int64 into a builtin type of int32, might lose precision!\n",
      "Saving value type of int64 into a builtin type of int32, might lose precision!\n",
      "Saving value type of int64 into a builtin type of int32, might lose precision!\n",
      "Saving value type of int64 into a builtin type of int32, might lose precision!\n",
      "Saving value type of int64 into a builtin type of int32, might lose precision!\n",
      "Saving value type of int64 into a builtin type of int32, might lose precision!\n",
      "Saving value type of int64 into a builtin type of int32, might lose precision!\n",
      "Saving value type of int64 into a builtin type of int32, might lose precision!\n",
      "Converting PyTorch Frontend ==> MIL Ops:  80%|████████  | 1889/2361 [00:01<00:00, 1731.33 ops/s]Saving value type of int64 into a builtin type of int32, might lose precision!\n",
      "Saving value type of int64 into a builtin type of int32, might lose precision!\n",
      "Saving value type of int64 into a builtin type of int32, might lose precision!\n",
      "Saving value type of int64 into a builtin type of int32, might lose precision!\n",
      "Saving value type of int64 into a builtin type of int32, might lose precision!\n",
      "Saving value type of int64 into a builtin type of int32, might lose precision!\n",
      "Saving value type of int64 into a builtin type of int32, might lose precision!\n",
      "Saving value type of int64 into a builtin type of int32, might lose precision!\n",
      "Converting PyTorch Frontend ==> MIL Ops:  93%|█████████▎| 2193/2361 [00:01<00:00, 1720.00 ops/s]Saving value type of int64 into a builtin type of int32, might lose precision!\n",
      "Saving value type of int64 into a builtin type of int32, might lose precision!\n",
      "Saving value type of int64 into a builtin type of int32, might lose precision!\n",
      "Saving value type of int64 into a builtin type of int32, might lose precision!\n",
      "Converting PyTorch Frontend ==> MIL Ops: 100%|█████████▉| 2360/2361 [00:01<00:00, 1785.41 ops/s]\n",
      "Running MIL frontend_pytorch pipeline: 100%|██████████| 5/5 [00:00<00:00, 18.93 passes/s]\n",
      "Running MIL default pipeline: 100%|██████████| 76/76 [00:02<00:00, 31.19 passes/s]\n",
      "Running MIL backend_neuralnetwork pipeline: 100%|██████████| 9/9 [00:00<00:00, 82.98 passes/s]\n",
      "Translating MIL ==> NeuralNetwork Ops:   6%|▌         | 90/1477 [00:00<00:02, 602.82 ops/s]Const freqs_imag.5 was already added.\n",
      "Const freqs_real.5 was already added.\n",
      "Const freqs_real.5 was already added.\n",
      "Const freqs_imag.5 was already added.\n",
      "Const freqs_imag.5 was already added.\n",
      "Const freqs_real.5 was already added.\n",
      "Translating MIL ==> NeuralNetwork Ops:  13%|█▎        | 192/1477 [00:00<00:03, 324.69 ops/s]Const freqs_real.5 was already added.\n",
      "Const freqs_imag.5 was already added.\n",
      "Translating MIL ==> NeuralNetwork Ops:  15%|█▌        | 226/1477 [00:00<00:04, 259.47 ops/s]Const freqs_imag.5 was already added.\n",
      "Const freqs_real.5 was already added.\n",
      "Const freqs_real.5 was already added.\n",
      "Const freqs_imag.5 was already added.\n",
      "Const freqs_imag.5 was already added.\n",
      "Const freqs_real.5 was already added.\n",
      "Const add_0 was already added.\n",
      "Translating MIL ==> NeuralNetwork Ops:  22%|██▏       | 322/1477 [00:01<00:05, 230.69 ops/s]Const freqs_real.5 was already added.\n",
      "Const freqs_imag.5 was already added.\n",
      "Const freqs_imag.5 was already added.\n",
      "Const freqs_real.5 was already added.\n",
      "Const freqs_real.5 was already added.\n",
      "Const freqs_imag.5 was already added.\n",
      "Const freqs_imag.5 was already added.\n",
      "Const freqs_real.5 was already added.\n",
      "Const add_0 was already added.\n",
      "Translating MIL ==> NeuralNetwork Ops:  26%|██▋       | 388/1477 [00:01<00:03, 295.52 ops/s]Const freqs_real.5 was already added.\n",
      "Const freqs_imag.5 was already added.\n",
      "Translating MIL ==> NeuralNetwork Ops:  29%|██▊       | 422/1477 [00:01<00:04, 260.92 ops/s]Const freqs_imag.5 was already added.\n",
      "Const freqs_real.5 was already added.\n",
      "Const freqs_real.5 was already added.\n",
      "Const freqs_imag.5 was already added.\n",
      "Const freqs_imag.5 was already added.\n",
      "Const freqs_real.5 was already added.\n",
      "Const add_0 was already added.\n",
      "Translating MIL ==> NeuralNetwork Ops:  33%|███▎      | 486/1477 [00:01<00:03, 323.40 ops/s]Const freqs_real.5 was already added.\n",
      "Const freqs_imag.5 was already added.\n",
      "Const freqs_imag.5 was already added.\n",
      "Const freqs_real.5 was already added.\n",
      "Translating MIL ==> NeuralNetwork Ops:  35%|███▌      | 523/1477 [00:01<00:03, 285.49 ops/s]Const freqs_real.5 was already added.\n",
      "Const freqs_imag.5 was already added.\n",
      "Const freqs_imag.5 was already added.\n",
      "Const freqs_real.5 was already added.\n",
      "Const add_0 was already added.\n",
      "Translating MIL ==> NeuralNetwork Ops:  41%|████      | 607/1477 [00:02<00:03, 270.93 ops/s]Const freqs_real.5 was already added.\n",
      "Const freqs_imag.5 was already added.\n",
      "Const freqs_imag.5 was already added.\n",
      "Const freqs_real.5 was already added.\n",
      "Const freqs_real.5 was already added.\n",
      "Const freqs_imag.5 was already added.\n",
      "Const freqs_imag.5 was already added.\n",
      "Const freqs_real.5 was already added.\n",
      "Const add_0 was already added.\n",
      "Translating MIL ==> NeuralNetwork Ops:  46%|████▋     | 684/1477 [00:02<00:02, 369.42 ops/s]Const freqs_real.5 was already added.\n",
      "Const freqs_imag.5 was already added.\n",
      "Const freqs_imag.5 was already added.\n",
      "Const freqs_real.5 was already added.\n",
      "Const freqs_real.5 was already added.\n",
      "Const freqs_imag.5 was already added.\n",
      "Const freqs_imag.5 was already added.\n",
      "Const freqs_real.5 was already added.\n",
      "Translating MIL ==> NeuralNetwork Ops:  52%|█████▏    | 761/1477 [00:02<00:01, 444.89 ops/s]Const freqs_real.5 was already added.\n",
      "Const freqs_imag.5 was already added.\n",
      "Const freqs_imag.5 was already added.\n",
      "Const freqs_real.5 was already added.\n",
      "Translating MIL ==> NeuralNetwork Ops:  55%|█████▍    | 811/1477 [00:02<00:01, 416.26 ops/s]Const freqs_real.5 was already added.\n",
      "Const freqs_imag.5 was already added.\n",
      "Const freqs_imag.5 was already added.\n",
      "Const freqs_real.5 was already added.\n",
      "Const add_0 was already added.\n",
      "Translating MIL ==> NeuralNetwork Ops:  58%|█████▊    | 861/1477 [00:02<00:01, 424.15 ops/s]Const freqs_real.5 was already added.\n",
      "Const freqs_imag.5 was already added.\n",
      "Const freqs_imag.5 was already added.\n",
      "Const freqs_real.5 was already added.\n",
      "Const freqs_real.5 was already added.\n",
      "Const freqs_imag.5 was already added.\n",
      "Const freqs_imag.5 was already added.\n",
      "Const freqs_real.5 was already added.\n",
      "Translating MIL ==> NeuralNetwork Ops:  64%|██████▎   | 940/1477 [00:02<00:01, 459.45 ops/s]Const freqs_real.5 was already added.\n",
      "Const freqs_imag.5 was already added.\n",
      "Const freqs_imag.5 was already added.\n",
      "Const freqs_real.5 was already added.\n",
      "Translating MIL ==> NeuralNetwork Ops:  67%|██████▋   | 988/1477 [00:02<00:01, 448.53 ops/s]Const freqs_real.5 was already added.\n",
      "Const freqs_imag.5 was already added.\n",
      "Const freqs_imag.5 was already added.\n",
      "Const freqs_real.5 was already added.\n",
      "Const add_0 was already added.\n",
      "Translating MIL ==> NeuralNetwork Ops:  70%|███████   | 1038/1477 [00:02<00:00, 441.40 ops/s]Const freqs_real.5 was already added.\n",
      "Const freqs_imag.5 was already added.\n",
      "Const freqs_imag.5 was already added.\n",
      "Const freqs_real.5 was already added.\n",
      "Const freqs_real.5 was already added.\n",
      "Const freqs_imag.5 was already added.\n",
      "Const freqs_imag.5 was already added.\n",
      "Const freqs_real.5 was already added.\n",
      "Translating MIL ==> NeuralNetwork Ops:  75%|███████▌  | 1115/1477 [00:03<00:00, 455.82 ops/s]Const freqs_real.5 was already added.\n",
      "Const freqs_imag.5 was already added.\n",
      "Const freqs_imag.5 was already added.\n",
      "Const freqs_real.5 was already added.\n",
      "Translating MIL ==> NeuralNetwork Ops:  79%|███████▊  | 1161/1477 [00:03<00:00, 370.45 ops/s]Const freqs_real.5 was already added.\n",
      "Const freqs_imag.5 was already added.\n",
      "Const freqs_imag.5 was already added.\n",
      "Const freqs_real.5 was already added.\n",
      "Const add_0 was already added.\n",
      "Translating MIL ==> NeuralNetwork Ops:  82%|████████▏ | 1215/1477 [00:03<00:00, 396.25 ops/s]Const freqs_real.5 was already added.\n",
      "Const freqs_imag.5 was already added.\n",
      "Const freqs_imag.5 was already added.\n",
      "Const freqs_real.5 was already added.\n",
      "Const freqs_real.5 was already added.\n",
      "Const freqs_imag.5 was already added.\n",
      "Const freqs_imag.5 was already added.\n",
      "Const freqs_real.5 was already added.\n",
      "Translating MIL ==> NeuralNetwork Ops:  88%|████████▊ | 1294/1477 [00:03<00:00, 458.00 ops/s]Const freqs_real.5 was already added.\n",
      "Const freqs_imag.5 was already added.\n",
      "Const freqs_imag.5 was already added.\n",
      "Const freqs_real.5 was already added.\n",
      "Const freqs_real.5 was already added.\n",
      "Const freqs_imag.5 was already added.\n",
      "Const freqs_imag.5 was already added.\n",
      "Const freqs_real.5 was already added.\n",
      "Const add_0 was already added.\n",
      "Translating MIL ==> NeuralNetwork Ops:  93%|█████████▎| 1378/1477 [00:03<00:00, 520.47 ops/s]Const freqs_real.5 was already added.\n",
      "Const freqs_imag.5 was already added.\n",
      "Const freqs_imag.5 was already added.\n",
      "Const freqs_real.5 was already added.\n",
      "Const freqs_real.5 was already added.\n",
      "Const freqs_imag.5 was already added.\n",
      "Const freqs_imag.5 was already added.\n",
      "Const freqs_real.5 was already added.\n",
      "Translating MIL ==> NeuralNetwork Ops: 100%|██████████| 1477/1477 [00:04<00:00, 364.55 ops/s]\n"
     ]
    }
   ],
   "source": [
    "mlmodel = ct.convert(model, \n",
    "                     inputs=[ct.TensorType(name=\"x\", shape=(1, 100), dtype=np.int32), ct.TensorType(name=\"originalText\", shape=(1, 100), dtype=np.int32)],\n",
    "                     convert_to=\"neuralnetwork\",\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlmodel.save(\"model.mlmodel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running compression pass prune_weights: 100%|██████████| 95/95 [00:01<00:00, 74.91 ops/s] \n",
      "Running MIL frontend_milinternal pipeline: 0 passes [00:00, ? passes/s]\n",
      "Running MIL default pipeline: 100%|██████████| 76/76 [00:01<00:00, 39.79 passes/s]\n",
      "Running MIL backend_mlprogram pipeline: 100%|██████████| 12/12 [00:00<00:00, 102.54 passes/s]\n"
     ]
    }
   ],
   "source": [
    "from coremltools.optimize.coreml import (\n",
    "    OpMagnitudePrunerConfig,\n",
    "    OptimizationConfig,\n",
    "    prune_weights,\n",
    ")\n",
    "\n",
    "op_config = OpMagnitudePrunerConfig(\n",
    "    target_sparsity=0.6,\n",
    "    weight_threshold=1024,\n",
    ")\n",
    "config = OptimizationConfig(global_config=op_config)\n",
    "model_compressed = prune_weights(mlmodel, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running compression pass palettize_weights:   0%|          | 0/160 [00:00<?, ? ops/s]/home/rahulvadhyar/.local/lib/python3.11/site-packages/sklearn/base.py:1474: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (256). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "Running compression pass palettize_weights:   5%|▌         | 8/160 [00:00<00:06, 24.11 ops/s]/home/rahulvadhyar/.local/lib/python3.11/site-packages/sklearn/base.py:1474: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (256). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "Running compression pass palettize_weights: 100%|██████████| 160/160 [00:00<00:00, 412.06 ops/s]\n",
      "Running MIL frontend_milinternal pipeline: 0 passes [00:00, ? passes/s]\n",
      "Running MIL default pipeline: 100%|██████████| 76/76 [00:01<00:00, 39.55 passes/s]\n",
      "Running MIL backend_mlprogram pipeline: 100%|██████████| 12/12 [00:00<00:00, 72.12 passes/s]\n"
     ]
    }
   ],
   "source": [
    "from coremltools.optimize.coreml import (\n",
    "    OpPalettizerConfig,\n",
    "    OptimizationConfig,\n",
    "    palettize_weights,\n",
    ")\n",
    "\n",
    "op_config = OpPalettizerConfig(mode=\"kmeans\", nbits=8, weight_threshold=512)\n",
    "config = OptimizationConfig(global_config=op_config)\n",
    "compressed_6_bit_model = palettize_weights(model_compressed, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed_6_bit_model .save(\"model.mlpackage\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
